{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao da raiz do projeto\n",
    "\n",
    "PROJECT_ROOT = 'G:/Csouza/nlp/topic_modeling'\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "sys.path.insert(0, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(extract_path, file_name='all_process.xlsx', sheet_name='Sheet1'):\n",
    "    \n",
    "    return pl.read_excel(f'{extract_path}/{file_name}', sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(PROJECT_ROOT, 'data', 'internal', 'fapesp_projects')\n",
    "\n",
    "full_data = extract(data_path)\n",
    "\n",
    "variables = {\n",
    "'N. Processo_B.V': 'n_processo',\n",
    "'Data de Início': 'data',\n",
    "'Título (Português)': 'titulo',\n",
    "'Grande Área do Conhecimento': 'grande_area',\n",
    "'Área do Conhecimento': 'area',\n",
    "'Subárea do Conhecimento': 'subarea',\n",
    "'Palavras-Chave do Processo': 'palavras_chave',\n",
    "'Assuntos': 'assuntos',\n",
    "'Resumo (Português)': 'resumo'}\n",
    "\n",
    "full_data = (\n",
    "    full_data\n",
    "    .lazy()\n",
    "    .rename(variables)\n",
    "    .select(variables.values())\n",
    "    .filter(\n",
    "        pl.col('n_processo').is_not_null(),\n",
    "        pl.col('resumo').is_not_null(),\n",
    "        pl.col('resumo') != '')\n",
    "    .with_columns(\n",
    "        pl.col('data').str.to_datetime('%m-%d-%y').dt.year().alias('ano'),\n",
    "        pl.col('data').str.to_datetime('%m-%d-%y').dt.month().alias('mes'))\n",
    "    .select(pl.exclude('data'))\n",
    ").collect()\n",
    "\n",
    "full_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_test = full_data.filter(pl.col('assuntos').is_not_null(), pl.col('area') == 'Medicina')\n",
    "\n",
    "data_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_model(model='en_core_web_sm'):\n",
    "    \"\"\"\n",
    "    Baixa o modelo de linguagem spaCy se não estiver presente.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp = spacy.load(model)\n",
    "    except OSError:\n",
    "        from spacy.cli import download\n",
    "        download(model)\n",
    "        nlp = spacy.load(model)\n",
    "    return nlp\n",
    "\n",
    "# Carregar o modelo de linguagem em português do spaCy\n",
    "nlp = get_spacy_model('pt_core_news_sm')\n",
    "\n",
    "# Definir as stop words em português usando spaCy\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Compilador para remover caracteres especiais (exceto acentos e espaços)\n",
    "special_char_remover = re.compile(r'[^A-Za-zÀ-ÿ\\s]')\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"O argumento 'text' deve ser uma string.\")\n",
    "    \n",
    "    # Remover caracteres especiais\n",
    "    text = special_char_remover.sub('', text)\n",
    "    \n",
    "    # Tokenizar o texto e remover stop words\n",
    "    tokens = [token.text for token in nlp(text) if token.text not in stop_words]\n",
    "    \n",
    "    # Lematizar o texto\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    text = ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = data_train_test.to_pandas()\n",
    "\n",
    "data['titulo'] = data['titulo'].astype(str)\n",
    "data['palavras_chave'] = data['palavras_chave'].astype(str)\n",
    "\n",
    "data['cleaned_text'] = data['resumo'].apply(clean_text)\n",
    "data['cleaned_text'] += ' Título: ' + data['titulo'].apply(clean_text) + ' Palavras-chave: ' + data['palavras_chave'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em treino e teste\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenização com BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "train_tokenized_texts = tokenizer(train_data['cleaned_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_tokenized_texts = tokenizer(test_data['cleaned_text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Converte os assuntos em listas\n",
    "train_data['assuntos_list'] = train_data['assuntos'].apply(lambda x: x.split(':'))\n",
    "test_data['assuntos_list'] = test_data['assuntos'].apply(lambda x: x.split(':'))\n",
    "\n",
    "# Binariza os rótulos\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "train_binary_labels = mlb.fit_transform(train_data['assuntos_list'])\n",
    "test_binary_labels = mlb.transform(test_data['assuntos_list'])\n",
    "\n",
    "# Convertendo para tensores PyTorch\n",
    "train_binary_labels = torch.tensor(train_binary_labels, dtype=torch.float)\n",
    "test_binary_labels = torch.tensor(test_binary_labels, dtype=torch.float)\n",
    "\n",
    "# Criação de máscaras de atenção\n",
    "train_attention_mask = train_tokenized_texts['attention_mask']\n",
    "test_attention_mask = test_tokenized_texts['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo BERT pré-treinado\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(mlb.classes_))\n",
    "\n",
    "# Ajuste da camada de classificação para multi-rótulo\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.config.hidden_size, model.config.hidden_size),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(model.config.hidden_size, len(mlb.classes_)),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar todas as camadas do BERT\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar a última camada\n",
    "for param in model.bert.encoder.layer[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# A camada de classificação é treinada por padrão\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe Customizada para Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(outputs.logits.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(dataloader), np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "# Função para calcular métricas\n",
    "def compute_metrics(labels, preds, threshold=0.5):\n",
    "    preds = (preds > threshold).astype(int)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='samples')\n",
    "    recall = recall_score(labels, preds, average='samples')\n",
    "    precision = precision_score(labels, preds, average='samples')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de perda e otimizador\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5, eps=1e-8)  # Apenas atualiza os parâmetros que requerem gradiente\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Scheduler de taxa de aprendizado\n",
    "total_steps = len(train_tokenized_texts['input_ids']) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Criação dos DataLoaders\n",
    "train_dataset = CustomDataset(train_tokenized_texts, train_binary_labels)\n",
    "test_dataset = CustomDataset(test_tokenized_texts, test_binary_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de hiperparâmetros\n",
    "learning_rate = 1e-5\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "eps = 1e-8\n",
    "weight_decay = 0.01\n",
    "warmup_steps = 0\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "# Scheduler de taxa de aprendizado\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(PROJECT_ROOT, 'models')\n",
    "model_name = f'{model_path}/best_model.pt'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    # Loop de Treinamento e Avaliação\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    num_epochs = 3\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        \n",
    "        train_loss = train(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
    "        print(f'Training loss: {train_loss:.4f}')\n",
    "        \n",
    "        val_loss, val_labels, val_preds = evaluate(model, test_dataloader, criterion, device)\n",
    "        print(f'Validation loss: {val_loss:.4f}')\n",
    "        \n",
    "        metrics = compute_metrics(np.array(val_labels), np.array(val_preds))\n",
    "        print(f'Validation metrics: {metrics}')\n",
    "        \n",
    "        if metrics['f1'] > best_f1:\n",
    "            print(f'Saving best model with F1 score: {metrics[\"f1\"]:.4f}')\n",
    "            torch.save(model.state_dict(), model_name)\n",
    "            best_f1 = metrics['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo fine-tuned\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "model.eval()\n",
    "\n",
    "# Função para gerar embeddings\n",
    "def get_embeddings(texts, model, tokenizer):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.bert(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]  # Use [CLS] token embeddings\n",
    "    return embeddings\n",
    "\n",
    "# Gerar embeddings\n",
    "embeddings = get_embeddings(test_data['cleaned_text'].tolist(), model, tokenizer)\n",
    "\n",
    "# Verificar se os embeddings foram gerados corretamente\n",
    "if embeddings.size(0) == 0:\n",
    "    raise ValueError(\"Os embeddings gerados estão vazios.\")\n",
    "\n",
    "# Debug print para verificar os embeddings\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "\n",
    "# Inicializar BERTopic com um modelo de embeddings padrão\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "umap_model = UMAP(n_neighbors=3, n_components=2, metric='cosine', random_state=42)  # Ajuste n_neighbors conforme necessário\n",
    "topic_model = BERTopic(embedding_model=embedding_model, umap_model=umap_model)\n",
    "\n",
    "# Ajustar o modelo aos dados\n",
    "try:\n",
    "    topics, probabilities = topic_model.fit_transform(test_data['cleaned_text'].tolist(), embeddings.numpy())\n",
    "except ValueError as e:\n",
    "    raise ValueError(f\"Erro ao ajustar o modelo BERTopic: {e}\")\n",
    "\n",
    "# Verificar se os tópicos foram gerados corretamente\n",
    "if len(topics) == 0:\n",
    "    raise ValueError(\"Nenhum tópico foi gerado. Verifique os dados de entrada e os embeddings.\")\n",
    "\n",
    "# Debug print para verificar os tópicos\n",
    "print(f\"Number of topics: {len(set(topics))}\")\n",
    "\n",
    "# Verificar se os embeddings dos tópicos não são vazios antes da visualização\n",
    "if topic_model.topic_embeddings_ is not None:\n",
    "    if topic_model.topic_embeddings_.size == 0:\n",
    "        raise ValueError(\"Os embeddings dos tópicos estão vazios.\")\n",
    "else:\n",
    "    if topic_model.c_tf_idf_.size == 0:\n",
    "        raise ValueError(\"A matriz c_tf_idf_ dos tópicos está vazia.\")\n",
    "\n",
    "# Adicionar verificação de tamanho dos embeddings antes de visualizar os tópicos\n",
    "if topic_model.topic_embeddings_ is not None:\n",
    "    if topic_model.topic_embeddings_.shape[0] == 0 or topic_model.topic_embeddings_.shape[1] == 0:\n",
    "        raise ValueError(\"Os embeddings dos tópicos têm tamanho zero.\")\n",
    "else:\n",
    "    if topic_model.c_tf_idf_.shape[0] == 0 or topic_model.c_tf_idf_.shape[1] == 0:\n",
    "        raise ValueError(\"A matriz c_tf_idf_ dos tópicos tem tamanho zero.\")\n",
    "\n",
    "# Debug print para verificar os embeddings dos tópicos\n",
    "print(f\"Shape of topic embeddings: {topic_model.topic_embeddings_.shape if topic_model.topic_embeddings_ is not None else 'N/A'}\")\n",
    "print(f\"Shape of c_tf_idf_: {topic_model.c_tf_idf_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_get_embeddings(texts, bert_model, tokenizer, device='cpu'):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states[-2]\n",
    "    embeddings = hidden_states.mean(dim=1).cpu().numpy()  # Média dos embeddings e conversão para numpy array\n",
    "    return embeddings\n",
    "\n",
    "def batch_predict_labels(texts, model, tokenizer, threshold=0.5, top_k=None, device='cpu'):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "\n",
    "    preds = []\n",
    "    for prob in probs:\n",
    "        if top_k:\n",
    "            top_indices = np.argsort(prob)[-top_k:]  # Obter os índices dos top_k rótulos mais prováveis\n",
    "            pred = np.zeros(prob.shape)\n",
    "            pred[top_indices] = 1\n",
    "        else:\n",
    "            pred = (prob > threshold).astype(int)\n",
    "        preds.append(pred)\n",
    "    \n",
    "    return np.array(preds), probs\n",
    "\n",
    "def apply_bertopic(texts, topic_model, bert_model=None, tokenizer=None, use_bert_embeddings=False, device='cpu', top_n_topics=None, top_n_tokens=None):\n",
    "    if use_bert_embeddings and bert_model and tokenizer:\n",
    "        embeddings = batch_get_embeddings(texts, bert_model, tokenizer, device=device)\n",
    "        topics, _ = topic_model.transform(texts, embeddings=embeddings)  # Passar os embeddings aqui\n",
    "    else:\n",
    "        topics, _ = topic_model.transform(texts)\n",
    "    \n",
    "    topic_details = []\n",
    "    for topic in topics:\n",
    "        if topic != -1:\n",
    "            topic_tokens = topic_model.get_topic(topic)[:top_n_tokens] if top_n_tokens else topic_model.get_topic(topic)\n",
    "            topic_details.append((topic, topic_tokens))\n",
    "    \n",
    "    return topic_details[:top_n_topics] if top_n_topics else topic_details\n",
    "\n",
    "def consolidate_results(texts, model, tokenizer, topic_model, mlb, threshold=0.5, top_k=None, use_bert_embeddings=False, device='cpu', top_n_topics=None, top_n_tokens=None, method='bert'):\n",
    "    preds, probs = batch_predict_labels(texts, model, tokenizer, threshold, top_k, device)\n",
    "    known_labels = mlb.inverse_transform(preds)\n",
    "    \n",
    "    all_labels = []\n",
    "    topic_details = []\n",
    "\n",
    "    for i, (pred, prob) in enumerate(zip(preds, probs)):\n",
    "        if method == 'bert':\n",
    "            # Se estiver usando BERT, retorna os rótulos conhecidos\n",
    "            all_labels.append(known_labels[i])\n",
    "            topic_details.append([])\n",
    "        elif method == 'bertopic':\n",
    "            # Se estiver usando BERTopic, retorna os tópicos com seus tokens\n",
    "            topics = apply_bertopic([texts[i]], topic_model, bert_model=model, tokenizer=tokenizer, use_bert_embeddings=use_bert_embeddings, device=device, top_n_topics=top_n_topics, top_n_tokens=top_n_tokens)\n",
    "            topic_labels = [token for topic, tokens in topics for token in tokens]\n",
    "            all_labels.append(list(set(known_labels[i]) | set(topic_labels)))\n",
    "            topic_details.append(topics)\n",
    "        else:\n",
    "            # Se a probabilidade máxima for menor que o threshold, aplica BERTopic\n",
    "            if np.max(prob) < threshold:\n",
    "                topics = apply_bertopic([texts[i]], topic_model, bert_model=model, tokenizer=tokenizer, use_bert_embeddings=use_bert_embeddings, device=device, top_n_topics=top_n_topics, top_n_tokens=top_n_tokens)\n",
    "                topic_labels = [token for topic, tokens in topics for token in tokens]\n",
    "                all_labels.append(list(set(known_labels[i]) | set(topic_labels)))\n",
    "                topic_details.append(topics)\n",
    "            else:\n",
    "                all_labels.append(known_labels[i])\n",
    "                topic_details.append([])\n",
    "\n",
    "    return all_labels, topic_details\n",
    "\n",
    "def batch_predict(texts, model, tokenizer, topic_model, mlb, threshold=0.5, top_k=None, use_bert_embeddings=False, device='cpu', top_n_topics=None, top_n_tokens=None, method='bert'):\n",
    "    # Move model to device and set to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    if use_bert_embeddings:\n",
    "        bert_model = model\n",
    "        bert_model.to(device)\n",
    "        bert_model.eval()\n",
    "    \n",
    "    all_labels, topic_details = consolidate_results(texts, model, tokenizer, topic_model, mlb, threshold, top_k, use_bert_embeddings, device, top_n_topics, top_n_tokens, method)\n",
    "    return list(zip(all_labels, topic_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: o doença infeccioso poder dizimar humanidade século diferentes agente entanto vacina mudar curso história conferir imunidade proteção considerar grande avanço ciência século dezenovar em o Brasil Programa Nacional Imunizações criar    ser responsável coordenar ação vacinação país ver desempenho declinar último ano diminuição cobertura vacinal abaixo nível mínimo esperar não haver dúvida eficácia necessidade vacinação gestante objetivo principal proteger neonato infecção um problema equipe médico encontrar maternidade Sistema Único Saúde SUS durante internação parto anotação incompleto ear inconsistente cartão prénatal em o período pandemiar suspeitase situação ter agravar além existir pouco estudo cobertura vacinal gestante puérpero Brasil trabalho visar avaliar cobertura vacinal população gestante internar durante trabalho parto maternidade referência presidente prudente região Oeste Estado São Paulo Brasil avaliar conhecimento respeito importânciar vacina calendário vacinal brasileiro entre agosto    dezembro    ser fotografar vacina cartão prénatal ear caderneta gestante questionário sigiloso estruturar ser livremente preenchir paciente Título: determinação cobertura vacinal parturiente internar hospital público oeste Paulo Palavras-chave: CALENDARIO VACINAL PARTURIENTE PROGRAMA NACIONAL DE IMUNIZACAO\n",
      "Rótulos preditos: ('Diabetes mellitus experimental', 'Enzima conversora da angiotensina 2', 'Leucemia mieloide', 'Quimases', 'Retrovirus endógenos')\n",
      "\n",
      "Texto: o Projeto EMU Científico Aquisição cell sorter espectral caracterização multidimensional interação célula hematopoético microambiente medular doença maligno infeccioso visar permitir análises interação celular caracterização imunofenotípico ser tecir sanguíneo tecido complexidade estrutural o equipamento permitir pesquisador ganhar informação significativo frente realizar citômetro fluxo convencional permitir análise diversos parâmetro fenotípico mesmo análise além BD FACSDiscover S citômetro espectral cell sorter equipar    lasers    detector empregar análise espectral identificação caracterização população celular interesse inovador recurso criação imagem célula interceptar lasers tecnologia patentear exclusivo denominar BD CellView utilizar dedicar detector produção de esse respectivo informação por tratar citometro espectral acoplar cell sorter apresentar potencial aplicação projeto pesquisa associar presente proposta foco identificação subpopulação celular alto complexidade imunofenotípico metabólico permitir ganho informação importante compreensão mecanismos celular possar abordar contexto terapêutico visar tornar rápido aplicação célulastronco célula imune geneticamente modificar combater câncer regeneração tecidual testeer composto potencial antitumoral ear regenerativo doença infeccioso AU Título: EMU Científico Aquisição Cell Sorter Espectral caracterização multidimensional interação célula hematopoético microambiente medular doença maligno infeccioso Palavras-chave: CELULAS IMUNES CITOMETRIA ESPECTRAL HEMATOLOGIA HEMATOPOIESE INFECCAO INTERACAO CELULAR\n",
      "Rótulos preditos: ('Células-tronco hematopoéticas', 'Enterobacter', 'Herança multifatorial', 'Perfil genético', 'Toxicidade')\n",
      "\n",
      "Texto: o aumento caso doença renal crônico DRC caracterizar perda progressivo irreversível função renal associar alto mortalidade doença ser considerar grave problema saúde público mundial o arsenal terapêutico empregar tratamento conservador DRC baseiase aplicação droga inibidoro reninaangiotensinaaldosterona SRAA diurético imunosupressor em o entanto estratégia combinar ineficaz conter progressão DRC impedir avanço necessidade terapia renal substitutivo motivar comunidade médicocientífica pesquisar tratamento adjuvante terapia atualmente empregar em esse contexto dar literatura demonstrar terapia celular empregar célula tronco mesenquimal derivar tecido adiposo CTmTA associar uso bloqueador SRAA Losartan LOS promover efeito renoprotetor importante modelo nefropatia experimental outro estudo suger efeito benéfico advir mecanismos sinalização celular CTm ser capaz deflagrar secreção vesícula extracelular VE conter citocina fator crescimento fragmento RNA microambiente inflamaçãoO objetivo estudo analisar efeito renoprotetor aplicação VE extraír CTmTA modelo DRC grave o objetivo específico Verificar aplicação VE promover efeito equivamente àqueles obtido inoculação CTmTA inteira comparar vias inoculação SubCap IV aplicação VE CTmTA analisar efeito aplicação VE CTmTA Associação tratamento LOS fazer melhor paralelo condição prático clínico tratamento DRC Nossa hipótese efeito renoprotetor obter terapia celular decorr entrega mediador CTmTA secreção VE tecido hospedeiro este projeto pesquisa original competitivo potencial geração importante resultado técnico acadêmico se hipóteser estar correto tratamento VE mostrar equivalente tratamento CTmTA termos renoproteção achar representar importante passo Medicina translacional aplçicação VE oferecer risco intercorrêncio formação trombo devido tamanho diminuto possibilitar administração grande quantidade bioativo estar concentrado VE de o vista acadêmico descrição efeito VE DRC expandir significativo fronteira conhecimento mecanismos fisiopatológico DRC comunicação intercelular contribuindotanto difusão conhecimento formação aluno pesquisador produção de issertaçõestese publicação artigo científico relevante alto potencial citação impacto Utilizaremos rato Wistar macho submetir modelo DRC ablação renal    Nx o tratamento iniciar    dia indução DRC animal apresentar sinal clínicolaboratorial nefropatia avançado para verificação hipótese empregare    protocolo    CTmTA VE SubCap analisaremo efeito aplicação subcapsular CTmTA VE monoterapia    associação CTmTA VE    LOS SubCap estudarer efeito aplicação subcapsular CTmTA VE associar LOS    CTmTA VE IV analisaremo efeito injeção intravenoso CTmTA VE monoterapia    associação CTmTA VE    LOS IV verificaremos efeito injeção intravenoso CTmTA VE associado LOS o análise integrar resultado de esse protocolo permitir selecionar bom via administração bioproduto terapiar celular verificar interação terapia CTmTA VE bloqueio SRAA AU Título: Análise efeito renoprotetor inoculação vesícula extracelular derivar célula tronco mesenquimal diferentes via administração modelo Doença Renal Crônica avançar Palavras-chave: CELULAS TRONCO MESENQUIMAIS DOENCA RENAL CRONICA FIBROSE INFLAMACAO NEFROPATIA TERAPIA CELULAR\n",
      "Rótulos preditos: ('Células-tronco hematopoéticas', 'Elastina', 'Hemorragia subaracnóidea', 'Resposta humoral', 'Toxicidade')\n",
      "\n",
      "Texto: Lesões nervoso central apresentar alto complexidade termos consequência termos tratamento devido sensibilidader grau interação componente tendo vist urgência tratamento efetivo trauma raquimedular diferentes molécula ser investigar em esse contexto canabidiol CBD mostrar eficiente diversos modelo contribuir significativamente neuroproteçãor imunomodulação desde buscase aumentar efetividade CBD modificação estrutura molecular gerar derivar sintético o efetividade canabidiol sintético fluorar HUF mesmo aplicação CBD permitir redução dose bom controle eventual efeito colateral esperandose resultado significativo ser presente estudo investigar efetividade HUF mitigar resposta retrógrar medula espinal esmagamento raíz ventral ERV camundongo adulto para camundongo CBLJ fêmea    semana vida ser dividir grupo experimental ERV    veículo n ERV    CBD mgkg ipdiário n ERV    HUF mgkg ipdiário n o efetividade tratamento ser avaliado      semana lesão empregandose imunoistoquímico reatividade glial preservação sináptico coloração nissl sobrevivêncer motoneurônio eletroneuromiografia análise marcha CatWalk RTqPCR Título: emprego análogo fluorar canabidiol HUF axotomiar radicular neuroproteção imunomodulação recuperação funcional Palavras-chave: CANABIDIOL FUNCIONALIDADE HUF IMUNOMODULACAO LESAO MEDULAR NEUROPROTECAO\n",
      "Rótulos preditos: ('Avaliação econômica', 'Células-tronco hematopoéticas', 'Elastina', 'Genomas', 'Resposta humoral')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_texts = test_data['cleaned_text'].tolist()[0:4]\n",
    "\n",
    "threshold = 0.7\n",
    "top_k = 5\n",
    "top_n_topics = 3\n",
    "top_n_tokens = 5\n",
    "\n",
    "# Aplicar a predição em lote\n",
    "predicted_labels_and_topics = batch_predict(\n",
    "    texts=test_texts,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    topic_model=topic_model,\n",
    "    mlb=mlb,\n",
    "    threshold=threshold,\n",
    "    top_k=top_k,\n",
    "    use_bert_embeddings=True,  # Escolher se deseja usar embeddings do BERT\n",
    "    device='cpu',  # Ou 'cuda' se você estiver usando GPU\n",
    "    top_n_topics=top_n_topics,\n",
    "    top_n_tokens=top_n_tokens,\n",
    "    method='bert'\n",
    ")\n",
    "\n",
    "# Exibir os resultados\n",
    "for text, (labels, topics) in zip(test_texts, predicted_labels_and_topics):\n",
    "    print(f\"Texto: {text}\")\n",
    "    print(f\"Rótulos preditos: {labels}\")\n",
    "    if topics:\n",
    "        print(\"Tópicos e tokens associados:\")\n",
    "        for topic, tokens in topics:\n",
    "            print(f\"  Tópico {topic}: {tokens}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
