{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datasets import Dataset\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from bertopic import BERTopic\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao da raiz do projeto\n",
    "\n",
    "PROJECT_ROOT = 'G:/Csouza/nlp/topic_modeling'\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "sys.path.insert(0, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(extract_path):\n",
    "    csv_files = [file for file in os.listdir(extract_path) if file.endswith('.csv')]\n",
    "    schema = pl.read_csv(f'{extract_path}/{csv_files[0]}', ignore_errors=True, separator=';').schema\n",
    "                \n",
    "    dfs = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        full_file_path = os.path.join(extract_path, csv_file) \n",
    "        df = pl.read_csv(full_file_path, ignore_errors=True, schema=schema, separator=';')\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pl.concat(dfs)\n",
    "\n",
    "def get_spacy_model(model='en_core_web_sm'):\n",
    "    \"\"\"\n",
    "    Baixa o modelo de linguagem spaCy se não estiver presente.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp = spacy.load(model)\n",
    "    except OSError:\n",
    "        from spacy.cli import download\n",
    "        download(model)\n",
    "        nlp = spacy.load(model)\n",
    "    return nlp\n",
    "\n",
    "def preprocess_tokens(text, nlp_model=get_spacy_model(), special_char_remover=re.compile(r'[^A-Za-z\\s]')):\n",
    "    \"\"\"\n",
    "    Pré-processa o texto para uso em um modelo de PLN.\n",
    "\n",
    "    Args:\n",
    "    - text (str): Texto a ser pré-processado.\n",
    "    - nlp_model (spacy.language.Language): Modelo spaCy para processamento de linguagem natural.\n",
    "\n",
    "    Returns:\n",
    "    - str: Texto pré-processado.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"O argumento 'text' deve ser uma string.\")\n",
    "    \n",
    "    text = special_char_remover.sub('', text)\n",
    "    text = ' '.join(text.split())\n",
    "    text = text.lower()\n",
    "\n",
    "    doc = nlp_model(text)\n",
    "\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(PROJECT_ROOT, 'data', 'internal', 'fapesp_projects')\n",
    "\n",
    "data = extract(data_path)\n",
    "\n",
    "variables = {\n",
    "'N. Processo': 'n_processo',\n",
    "'Data de Início': 'data',\n",
    "'Título (Português)': 'titulo',\n",
    "'Grande Área do Conhecimento': 'grande_area',\n",
    "'Área do Conhecimento': 'area',\n",
    "'Subárea do Conhecimento': 'subarea',\n",
    "'Assuntos': 'assuntos',\n",
    "'Resumo (Português)': 'resumo'}\n",
    "\n",
    "data = (\n",
    "    data\n",
    "    .lazy()\n",
    "    .rename(variables)\n",
    "    .select(variables.values())\n",
    "    .filter(\n",
    "        pl.col('n_processo').is_not_null(),\n",
    "        pl.col('resumo').is_not_null(),\n",
    "        pl.col('resumo') != '')\n",
    "    .with_columns(\n",
    "        pl.col('data').str.to_datetime('%Y-%m-%d').dt.year().alias('ano'),\n",
    "        pl.col('data').str.to_datetime('%Y-%m-%d').dt.month().alias('mes'))\n",
    "    .select(pl.exclude('data'))\n",
    ").collect()\n",
    "\n",
    "data.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
