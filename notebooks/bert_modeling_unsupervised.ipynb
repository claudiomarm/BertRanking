{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\csouza\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\academic-fingerprint-4AictD0y-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments, BertModel\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao da raiz do projeto\n",
    "\n",
    "PROJECT_ROOT = 'G:/Csouza/nlp/topic_modeling'\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "sys.path.insert(0, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(extract_path, file_name='all_process.xlsx', sheet_name='Sheet1'):\n",
    "    return pd.read_excel(f'{extract_path}/{file_name}', sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(PROJECT_ROOT, 'data', 'internal', 'fapesp_projects')\n",
    "\n",
    "full_data = extract(data_path)\n",
    "\n",
    "variables = {\n",
    "'N. Processo_B.V': 'n_processo',\n",
    "'Data de Início': 'data',\n",
    "'Título (Português)': 'titulo',\n",
    "'Grande Área do Conhecimento': 'grande_area',\n",
    "'Área do Conhecimento': 'area',\n",
    "'Subárea do Conhecimento': 'subarea',\n",
    "'Palavras-Chave do Processo': 'palavras_chave',\n",
    "'Assuntos': 'assuntos',\n",
    "'Resumo (Português)': 'resumo'}\n",
    "\n",
    "full_data = full_data.rename(columns=variables)\n",
    "\n",
    "# Selecionar colunas específicas\n",
    "full_data = full_data[list(variables.values())]\n",
    "\n",
    "# Filtrar linhas com base em condições\n",
    "full_data = full_data[\n",
    "    full_data['n_processo'].notnull() &\n",
    "    full_data['resumo'].notnull() &\n",
    "    (full_data['resumo'] != '')\n",
    "]\n",
    "\n",
    "# Adicionar novas colunas com base em transformações de colunas existentes\n",
    "full_data['data'] = pd.to_datetime(full_data['data'], format='%m-%d-%y', errors='coerce')\n",
    "full_data['ano'] = full_data['data'].dt.year\n",
    "full_data['mes'] = full_data['data'].dt.month\n",
    "\n",
    "# Excluir a coluna 'data'\n",
    "full_data = full_data.drop(columns=['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_processo</th>\n",
       "      <th>titulo</th>\n",
       "      <th>grande_area</th>\n",
       "      <th>area</th>\n",
       "      <th>subarea</th>\n",
       "      <th>palavras_chave</th>\n",
       "      <th>assuntos</th>\n",
       "      <th>resumo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95/04916-0</td>\n",
       "      <td>Estudo sistemático de campos hiperfinos eletro...</td>\n",
       "      <td>Ciências Exatas e da Terra</td>\n",
       "      <td>Física</td>\n",
       "      <td>Física da Matéria Condensada</td>\n",
       "      <td>CORRELACAO ANGULAR, ESTUDO SISTEMATICO, INTERA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Este projeto está vinculado ao processo FAPESP...</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95/05064-7</td>\n",
       "      <td>Cultura, ideologia e representação</td>\n",
       "      <td>Ciências Humanas</td>\n",
       "      <td>Sociologia</td>\n",
       "      <td>Outras Sociologias Específicas</td>\n",
       "      <td>BRASIL, IDENTIDADE, PENSAMENTO SOCIAL, REPRESE...</td>\n",
       "      <td>Brasil:Identidade social</td>\n",
       "      <td>Participar do Seminário \"\"Sociologia e Filosof...</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95/09836-4</td>\n",
       "      <td>Bernard Schmitt | Université de Bourgogne - Fr...</td>\n",
       "      <td>Ciências Exatas e da Terra</td>\n",
       "      <td>Probabilidade e Estatística</td>\n",
       "      <td>Probabilidade</td>\n",
       "      <td>COMPRESSOR, ENTROPIA, ESTADO DE GIBBS, SISTEMA...</td>\n",
       "      <td>Entropia (matemática aplicada):Compressores</td>\n",
       "      <td>O principal objetivo da visita do Professor Be...</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_processo                                             titulo  \\\n",
       "0   95/04916-0  Estudo sistemático de campos hiperfinos eletro...   \n",
       "6   95/05064-7                 Cultura, ideologia e representação   \n",
       "22  95/09836-4  Bernard Schmitt | Université de Bourgogne - Fr...   \n",
       "\n",
       "                   grande_area                         area  \\\n",
       "0   Ciências Exatas e da Terra                       Física   \n",
       "6             Ciências Humanas                   Sociologia   \n",
       "22  Ciências Exatas e da Terra  Probabilidade e Estatística   \n",
       "\n",
       "                           subarea  \\\n",
       "0     Física da Matéria Condensada   \n",
       "6   Outras Sociologias Específicas   \n",
       "22                   Probabilidade   \n",
       "\n",
       "                                       palavras_chave  \\\n",
       "0   CORRELACAO ANGULAR, ESTUDO SISTEMATICO, INTERA...   \n",
       "6   BRASIL, IDENTIDADE, PENSAMENTO SOCIAL, REPRESE...   \n",
       "22  COMPRESSOR, ENTROPIA, ESTADO DE GIBBS, SISTEMA...   \n",
       "\n",
       "                                       assuntos  \\\n",
       "0                                           NaN   \n",
       "6                      Brasil:Identidade social   \n",
       "22  Entropia (matemática aplicada):Compressores   \n",
       "\n",
       "                                               resumo   ano  mes  \n",
       "0   Este projeto está vinculado ao processo FAPESP...  1995   12  \n",
       "6   Participar do Seminário \"\"Sociologia e Filosof...  1995   12  \n",
       "22  O principal objetivo da visita do Professor Be...  1995   12  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17342, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_test = full_data[full_data['assuntos'].notnull() & (full_data['area'] == 'Medicina')]\n",
    "data_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\csouza\\AppData\\Local\\Temp\\ipykernel_17044\\3606267729.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['titulo'] = data['titulo'].astype(str)\n",
      "C:\\Users\\csouza\\AppData\\Local\\Temp\\ipykernel_17044\\3606267729.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['palavras_chave'] = data['palavras_chave'].astype(str)\n",
      "C:\\Users\\csouza\\AppData\\Local\\Temp\\ipykernel_17044\\3606267729.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cleaned_text'] = data['titulo'].apply(clean_text) + '. ' + data['resumo'].apply(clean_text) + '. Palavras-chave: ' + data['palavras_chave'].apply(clean_text)\n",
      "C:\\Users\\csouza\\AppData\\Local\\Temp\\ipykernel_17044\\3606267729.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['assuntos'] = data['assuntos'].apply(lambda x: [s.strip() for s in str(x).split(':')])\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"O argumento 'text' deve ser uma string.\")\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-ZÀ-ÿ0-9\\s]', '', text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Carregar os dados\n",
    "data = data_train_test\n",
    "\n",
    "data['titulo'] = data['titulo'].astype(str)\n",
    "data['palavras_chave'] = data['palavras_chave'].astype(str)\n",
    "\n",
    "# Aplicar a limpeza de texto sem remover stop words\n",
    "data['cleaned_text'] = data['titulo'].apply(clean_text) + '. ' + data['resumo'].apply(clean_text) + '. Palavras-chave: ' + data['palavras_chave'].apply(clean_text)\n",
    "\n",
    "data['assuntos'] = data['assuntos'].apply(lambda x: [s.strip() for s in str(x).split(':')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Map: 100%|██████████| 17342/17342 [00:57<00:00, 299.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "bert_model = BertForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "\n",
    "# Função de tokenização para MLM\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['cleaned_text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "dataset = Dataset.from_pandas(data)\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Dividir em conjunto de treino e teste\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "# Data collator para MLM (vai automaticamente mascarar tokens)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tokenizer, train_dataset, test_dataset, data_collator, model_path, tokenizer_path, output_dir, overwrite_output_dir=True, save_steps=10_000, save_total_limit=2, prediction_loss_only=True, num_train_epochs=3, per_device_train_batch_size=8):    \n",
    "    \n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    os.makedirs(tokenizer_path, exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=overwrite_output_dir,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=save_total_limit,\n",
    "        prediction_loss_only=prediction_loss_only,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo\n",
    "    trainer.train()\n",
    "\n",
    "    # Salvar o modelo e o tokenizer\n",
    "    if model_path:\n",
    "        trainer.save_model(model_path)\n",
    "    \n",
    "    if tokenizer_path:\n",
    "        tokenizer.save_pretrained(tokenizer_path)\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "def evaluate_model(trainer, test_dataset):\n",
    "    eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "    loss = eval_results['eval_loss']\n",
    "    perplexity = np.exp(loss)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'perplexity': perplexity\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def get_embeddings(texts, model, tokenizer, max_length=512, batch_size=8):\n",
    "    if not hasattr(model, \"is_on_device\"):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        model.is_on_device = True\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_length).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    return all_embeddings\n",
    "\n",
    "def generate_embeddings(dataset, text_col='cleaned_text', topic_col='assuntos', batch_size=8):\n",
    "    texts = dataset[text_col]\n",
    "    dataset['text_embedding'] = get_embeddings(texts, bert_model, tokenizer, batch_size=batch_size)\n",
    "    \n",
    "    all_assuntos = dataset[topic_col]\n",
    "    all_assuntos_embeddings = []\n",
    "    for subjects in all_assuntos:\n",
    "        subjects_embeddings = get_embeddings(subjects, bert_model, tokenizer, batch_size=batch_size)\n",
    "        all_assuntos_embeddings.append(subjects_embeddings)\n",
    "    \n",
    "    dataset['topics_embeddings'] = all_assuntos_embeddings\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(PROJECT_ROOT, 'models')\n",
    "tokenizer_path = os.path.join(PROJECT_ROOT, 'tokenizers')\n",
    "results_path = os.path.join(model_path, 'results')\n",
    "\n",
    "model_exists = os.path.isfile(os.path.join(model_path, 'model.safetensors')) and os.path.isfile(os.path.join(model_path, 'config.json'))\n",
    "tokenizer_exists = os.path.isfile(os.path.join(tokenizer_path, 'vocab.txt'))\n",
    "\n",
    "# Treinar o modelo se ele não existir\n",
    "if not model_exists or not tokenizer_exists:\n",
    "    print(\"Modelo treinado não encontrado. Iniciando o treinamento...\")\n",
    "    trainer = train_model(\n",
    "        model=bert_model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        model_path=model_path,\n",
    "        tokenizer_path=tokenizer_path,\n",
    "        output_dir=results_path\n",
    "    )\n",
    "\n",
    "    metrics = evaluate_model(trainer, test_dataset)\n",
    "    print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at G:/Csouza/nlp/topic_modeling\\models and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
    "bert_model = BertModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de Embeddings com BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3469/3469 [3:19:20<00:00,  3.45s/ examples]  \n"
     ]
    }
   ],
   "source": [
    "embedding_path = os.path.join(PROJECT_ROOT, 'data', 'processed', 'fapesp_projects', 'test_dataset_with_embeddings.parquet')\n",
    "\n",
    "def save_dataset(dataset, path):\n",
    "    df = dataset.to_pandas()\n",
    "    df.to_parquet(path, index=False)\n",
    "\n",
    "def load_dataset(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "if os.path.exists(embedding_path):\n",
    "    print(\"Carregando test_dataset do arquivo salvo...\")\n",
    "    test_dataset = load_dataset(embedding_path)\n",
    "else:\n",
    "    print(\"Gerando embeddings e salvando test_dataset...\")\n",
    "    \n",
    "    BATCH_SIZE = 8\n",
    "    test_dataset = test_dataset.map(generate_embeddings, batched=True, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    save_dataset(test_dataset, embedding_path)\n",
    "    print(\"test_dataset salvo com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranqueamento dos Assuntos por Relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3469/3469 [00:13<00:00, 265.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular a relevância dos tópicos\n",
    "def rank_topics_by_relevance(text_embedding, topics_embeddings, topics):\n",
    "    # Converter os embeddings para arrays NumPy, caso sejam listas\n",
    "    text_embedding = np.array(text_embedding)\n",
    "    topics_embeddings = [np.array(topic_emb) for topic_emb in topics_embeddings]\n",
    "    \n",
    "    # Calcular similaridades de cosseno entre o embedding do texto e cada embedding dos tópicos\n",
    "    similarities = [cosine_similarity(text_embedding.reshape(1, -1), topic_emb.reshape(1, -1))[0, 0] for topic_emb in topics_embeddings]\n",
    "    \n",
    "    # Classificar os tópicos de acordo com a similaridade, do maior para o menor\n",
    "    ranked_topics = sorted(zip(topics, similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Retornar apenas os tópicos ranqueados\n",
    "    return [topic for topic, _ in ranked_topics]\n",
    "\n",
    "# Aplicar o ranqueamento dos tópicos ao dataset de teste\n",
    "def rank_topics(dataset, text_embedding_col='text_embedding', topics_embeddings_col='topics_embeddings', topics_col='assuntos'):\n",
    "    dataset['ranked_topics'] = rank_topics_by_relevance(dataset[text_embedding_col], dataset[topics_embeddings_col], dataset[topics_col])\n",
    "    return dataset\n",
    "\n",
    "test_dataset = test_dataset.map(rank_topics, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no Top-3: 1.00\n",
      "Recall no Top-3: 0.71\n",
      "NDCG no Top-3: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular precisão no top-k\n",
    "def precision_at_k(true_labels, predicted_labels, k):\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        predicted_top_k = predicted[:k]\n",
    "        if any(subject in predicted_top_k for subject in true):\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    return correct_predictions / len(true_labels)\n",
    "\n",
    "# Função para calcular recall no top-k\n",
    "def recall_at_k(true_labels, predicted_labels, k):\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        predicted_top_k = predicted[:k]\n",
    "        correct_in_top_k = len(set(true) & set(predicted_top_k))\n",
    "        total_relevant = len(true)\n",
    "        \n",
    "        if total_relevant > 0:\n",
    "            correct_predictions += correct_in_top_k / total_relevant\n",
    "    \n",
    "    return correct_predictions / len(true_labels)\n",
    "\n",
    "# Função para calcular DCG\n",
    "def dcg_at_k(relevances, k):\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    return np.sum((2**relevances - 1) / np.log2(np.arange(2, len(relevances) + 2)))\n",
    "\n",
    "# Função para calcular NDCG no top-k\n",
    "def ndcg_at_k(true_labels, predicted_labels, k):\n",
    "    total_ndcg = 0.0\n",
    "    \n",
    "    for true, predicted in zip(true_labels, predicted_labels):\n",
    "        # Atribuir relevância: 1 para tópicos verdadeiros, 0 para os outros\n",
    "        relevances = [1 if topic in true else 0 for topic in predicted[:k]]\n",
    "        dcg = dcg_at_k(relevances, k)\n",
    "        ideal_relevances = sorted(relevances, reverse=True)\n",
    "        idcg = dcg_at_k(ideal_relevances, k)\n",
    "        \n",
    "        if idcg > 0:\n",
    "            total_ndcg += dcg / idcg\n",
    "    \n",
    "    return total_ndcg / len(true_labels)\n",
    "\n",
    "# Extrair os dados do Dataset Hugging Face para listas\n",
    "true_labels = test_dataset['assuntos']\n",
    "predicted_labels = test_dataset['ranked_topics']\n",
    "\n",
    "# Calcular as métricas no Top-3\n",
    "k = 3\n",
    "precision = precision_at_k(true_labels, predicted_labels, k)\n",
    "recall = recall_at_k(true_labels, predicted_labels, k)\n",
    "ndcg = ndcg_at_k(true_labels, predicted_labels, k)\n",
    "\n",
    "# Imprimir as métricas\n",
    "print(f\"Precisão no Top-{k}: {precision:.2f}\")\n",
    "print(f\"Recall no Top-{k}: {recall:.2f}\")\n",
    "print(f\"NDCG no Top-{k}: {ndcg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 5\n",
    "\n",
    "for i in range(num_examples):\n",
    "    example = test_dataset[i]\n",
    "    \n",
    "    print(f\"Resumo: {example['cleaned_text']}\")\n",
    "    print(f\"Tópicos Reais: {example['assuntos']}\")\n",
    "    print(f\"Tópicos Ranqueados: {example['ranked_topics']}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo da Similaridade Semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a similaridade de cosseno média para cada modelo\n",
    "def calculate_mean_cosine_similarity(text_embeddings, topics_embeddings):\n",
    "    all_similarities = []\n",
    "    for text_emb, topic_embs in zip(text_embeddings, topics_embeddings):\n",
    "        similarities = [cosine_similarity(text_emb.reshape(1, -1), topic_emb.reshape(1, -1))[0, 0]\n",
    "                        for topic_emb in topic_embs]\n",
    "        all_similarities.append(np.mean(similarities))  # Calcular média de similaridades para cada resumo\n",
    "    return np.array(all_similarities)\n",
    "\n",
    "# Função para comparar dois modelos (BERTimbau vs RoBERTa) por similaridade semântica\n",
    "def compare_models_by_semantic_similarity(bert_similarities, roberta_similarities):\n",
    "    # Comparação de métricas\n",
    "    mean_similarity_bert = np.mean(bert_similarities)\n",
    "    mean_similarity_roberta = np.mean(roberta_similarities)\n",
    "\n",
    "    std_similarity_bert = np.std(bert_similarities)\n",
    "    std_similarity_roberta = np.std(roberta_similarities)\n",
    "\n",
    "    print(f\"Média Similaridade (BERTimbau): {mean_similarity_bert:.2f}\")\n",
    "    print(f\"Média Similaridade (RoBERTa): {mean_similarity_roberta:.2f}\")\n",
    "    print(f\"Desvio Padrão Similaridade (BERTimbau): {std_similarity_bert:.2f}\")\n",
    "    print(f\"Desvio Padrão Similaridade (RoBERTa): {std_similarity_roberta:.2f}\")\n",
    "\n",
    "    # Plotando a Distribuição das Similaridades\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(bert_similarities, color='blue', label='BERTimbau', kde=True, bins=20)\n",
    "    sns.histplot(roberta_similarities, color='green', label='RoBERTa', kde=True, bins=20)\n",
    "    plt.title('Distribuição das Similaridades de Cosseno: BERTimbau vs RoBERTa')\n",
    "    plt.xlabel('Similaridade de Cosseno')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot para Comparação de Similaridades\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=[bert_similarities, roberta_similarities], palette='Set2')\n",
    "    plt.xticks([0, 1], ['BERTimbau', 'RoBERTa'])\n",
    "    plt.title('Comparação da Similaridade de Cosseno: BERTimbau vs RoBERTa')\n",
    "    plt.ylabel('Similaridade de Cosseno')\n",
    "    plt.show()\n",
    "\n",
    "bert_similarities = calculate_mean_cosine_similarity(test_dataset['text_embedding'], test_dataset['topics_embeddings'])\n",
    "\n",
    "# roberta_similarities = calculate_mean_cosine_similarity(test_dataset['text_embedding'], test_dataset['topics_embeddings_roberta'])\n",
    "\n",
    "# Comparar BERTimbau com RoBERTa quando RoBERTa estiver disponível\n",
    "# compare_models_by_semantic_similarity(bert_similarities, roberta_similarities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academic-fingerprint-4AictD0y-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
